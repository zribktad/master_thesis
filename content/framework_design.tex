%!TEX root = ../main.tex

\chapter{Framework Design\label{chap:framework_design}}

This chapter provides a detailed analysis of the framework's requirements, its architecture, and the individual components that facilitate the fulfillment of performance, modularity, and seamless integration requirements. The solution is composed of several foundational layers that complement each other, offering flexibility for diverse use cases. The primary goal is to ensure that the framework effectively supports various testing scenarios with differing data requirements.

\section{Framework Requirements}

The primary goal of the framework extension is to
enhance the existing unit testing capabilities by integrating advanced data preparation and handling mechanisms.
Unit testing is a critical practice in modern software development,
ensuring that individual components of an application behave as expected.
However, setting up and managing test data can often become a cumbersome process,
especially in complex systems where tests depend on intricate data structures,
external services, or specific state configurations.
\subsection*{Functional Requirements}

\begin{itemize}
	\item \textbf{Custom Data Preparation Attributes:}
	      \begin{itemize}
		      \item Implement distinct custom attributes for defining data preparation methods and for utilizing prepared data within tests.
		      \item Ensure attributes for data preparation methods specify setup and teardown processes, supporting reuse across multiple test cases.
		      \item Design attributes to allow the injection parameterized data, enabling differentiation for tests requiring similar preparation but with varying input parameters.
		      \item Provide mechanisms for conditional test execution based on the prepared data state to ensure test reliability and flexibility.
	      \end{itemize}

	\item \textbf{Automated Test Data Handling:}
	      \begin{itemize}
		      \item Develop a mechanism to automate the execution of data preparation methods before and after tests, ensuring a consistent and reliable test environment.
		      \item Ensure seamless preparation and injection of both simple and complex test data structures to support diverse testing scenarios.
	      \end{itemize}

	\item \textbf{Data Preparation Store:}
	      \begin{itemize}
		      \item Develop a centralized store to maintain mappings of data preparation instances associated with test methods, enabling efficient and organized data management.
		      \item Ensure thread-safe access to support concurrent test executions in multi-threaded environments.
	      \end{itemize}

	\item \textbf{Integration with NUnit Test Lifecycle:}
	      \begin{itemize}
		      \item Integrate custom behaviors into the test execution lifecycle to include steps for data preparation and cleanup.
		      \item Ensure that custom lifecycle hooks are compatible with parallel test execution to maintain consistency in multi-threaded scenarios.
	      \end{itemize}

	\item \textbf{Attribute Count Tracking:}
	      \begin{itemize}
		      \item Develop a mechanism to track the execution of custom attributes and ensure that all necessary data preparations are completed before testing execution begins.
		      \item Avoid redundancy in data preparation by coordinating attribute behavior for tests with multiple attributes applied.
	      \end{itemize}

	\item \textbf{Service Provider Utilization:}
	      \begin{itemize}
		      \item Use a service provider pattern to manage dependencies and services required for data preparation.
		      \item Support integration with dependency injection frameworks.
	      \end{itemize}
	\item \textbf{Interface Usage:}
	      \begin{itemize}
		      \item Define clear and reusable interfaces for data preparation and cleanup logic to promote consistency and scalability across the framework.
		      \item Ensure that the interfaces allow developers to implement custom preparation methods tailored to specific testing requirements.
	      \end{itemize}
\end{itemize}

\subsection*{Non-Functional Requirements}

\begin{itemize}
	\item \textbf{Performance Efficiency:}
	      \begin{itemize}
		      \item Ensure minimal overhead is introduced during test execution to maintain optimal performance.
		      \item Optimize data preparation logic to minimize unnecessary computation or resource usage.
	      \end{itemize}

	\item \textbf{Modularity and Extensibility:}
	      \begin{itemize}
		      \item Design the framework with a modular architecture to facilitate easy maintenance and future enhancements.
		      \item Provide extension points for developers to customize or extend attributes and lifecycle handling.
	      \end{itemize}

	\item \textbf{Compliance with Coding Standards:}
	      \begin{itemize}
		      \item Ensure high-quality and easily readable code by strictly following established coding best practices and standards.
		      \item Follow the \href{https://en.wikipedia.org/wiki/SOLID}{SOLID}\footnote{The SOLID principles are a set of five design guidelines aimed at improving the clarity, flexibility, and maintainability of object-oriented software.} principles for maintainable and testable code.
	      \end{itemize}

	\item \textbf{Seamless NUnit Integration:}
	      \begin{itemize}
		      \item The extension should integrate smoothly with the existing NUnit framework without disrupting current testing workflows.
		      \item Support legacy NUnit test cases alongside the new extension.
	      \end{itemize}
	\item \textbf{Documentation and User Guidance:}
	      \begin{itemize}
		      \item Provide comprehensive documentation, including user guides, examples, and FAQs, to simplify the adoption and usage of the framework.
		      \item Include inline comments within the codebase to explain key implementation details and design choices.
		      \item Offer troubleshooting steps and recommendations for common integration or usage challenges.
	      \end{itemize}
\end{itemize}

% Your content here.

\section{Framework Architecture}

The architecture of the framework is carefully designed to ensure scalability,
maintainability, and seamless integration with existing unit testing workflows.

The framework architecture is divided into two main components. The first component focuses on data preparation, while the second encompasses the test case, which includes the tests themselves. Except for specific framework elements, the test case retains the same components as those used in NUnit testing. The framework extends the functionality of the test case by defining whether it should be executed, specifying the framework services required for the test case, and identifying the prepared data to be used for individual tests.

Data preparation represents an additional feature compared to standard testing and requires developers to become familiar with its implementation when using the framework. The design of the data preparation component is structured to support both class-level and method-level test data preparation. The primary task for developers is to create a class associated, for example, with a specific tested method. The class does not require a constructor unless the developer requires dependencies on specific services. Instead, it only needs to define methods for setting up the data and for cleaning up the prepared data after testing.

This architectural approach ensures that the framework provides added value through structured data preparation while maintaining compatibility with known NUnit-based test case practices. The framework design is intended to be intuitive and easy to use, requiring minimal effort to adapt to the new data preparation features. The architecture is designed to be scalable and extensible, allowing developers to add new features and functionalities as needed. The modular design of the framework ensures that each component can be easily replaced or extended without affecting the overall functionality of the system.

It is structured into distinct layers,
each fulfilling specific responsibilities while adhering to the principles of modular design and separation of concerns. The following subsections describe the primary components of the architecture.

\subsection{Attributes Layer}

The \textit{Attributes Layer} is designed to facilitate the management of test data and the configuration of test frameworks. Almost every attribute in this layer serves as a directive indicating that a particular test case or method requires the preparation and use of specific data. The attributes provide a structured way to manage data setup and cleaning and ensure that the necessary data conditions are met before and after testing execution. The main reason to use attributes is to allow the programmer to extend the functionality of the NUnit framework and to ensure that there is no significant change in the process of how the tests are created and that the programmer does not need to spend too much effort to extend the knowledge of how the tests are created. The result is that the testing will be almost the same as before the extension of the framework and that there will be no need to learn new procedures or approaches to testing.


\subsection*{Attributes for Data Preparation}

The \textit{Attributes for Data Preparation} layer is designed to manage the setup and cleanup of test data within testing. The attributes serve as directives that indicate specific data requirements for test cases or methods. Provide a structured way to prepare, call, and remove prepared test data.  Ensure that the test environment is properly configured and that the conditions for the test data are met before, during, and after the execution of the test. This layer provides a unified approach to data set manipulation that enables precise control over data preparation management, which is essential to maintain the robustness and maintainability of the test procedures.

The attributes for data preparation for a class or method are different, but the data preparation structure is the same. This structure ensures a uniform approach to data preparation management, which is key to maintaining the robustness and maintainability of test practices. Instead of forcing programmers to implement the data preparation structure for each test method separately, it allows them to simply use the prepared data techniques and ensure that they are used correctly.
Although the data preparation structure is the same for class-prepared and method-prepared data, there are differences in how these attributes are used and how they affect test scenarios. The attributes for preparing data for a class allow you to define the methods for preparing data that are necessary for testing the whole class. The attributes ensure that the data preparation methods are properly configured and initialized according to the test scenario. The data preparation method attributes allow for more precise control over the preparation of data specific to a particular test scenario. 
All attributes support parameterized data inputs, allowing resolution for tests that have similar preparation requirements but different input parameters. The addition of parameters ensures that the data preparation is appropriate to the specific test requirements and that the data preparation can be dynamically changed according to the needs of the test.

The data preparation structure is created by the programmer independently. Consists of identification for which class or method the programmer wants to prepare the data with regard to what the given attribute will help, and enables the programmer to arrange the given structure to the class or method.

\subsection*{Testing Attributes}\label{subs:test_attrib}

The test attributes help define the test scenarios in which test data need to be prepared and used. Each of the attributes provides unique properties that allow for different data processing configurations. The base test attribute determines if the framework is to be used at all for a given test case. Other attributes are dedicated to calling data preparation for different tests as well as subsequent data rollback. By defining the attributes for a test, it is possible to specify more precisely how the data should be prepared and used. Data processing can be tailored to the specific requirements of the test, ensuring the data are accurately prepared.
Ensure that the necessary services are configured and initialized according to the unique requirements of each test scenario.

The attributes are divided into two main types. The first is an attribute that identifies that a specific test data is to be used for a given test method or class. Recognizable by the \textit{For} expression. The second type of attribute allows us to call the prepared data directly without knowing which method or class is used in the test. The design allows the programmer to easily access the prepared data during test execution. Enables precise selection of data sources needed for a given test.

In the above cases, we discuss calls to prepared data that have no parameters or do not need them. An extended version of these attributes are attributes that allow the use of parameters to define the preparation and manipulation of test data. The attributes allow for more precise control over how the data is manipulated on the basis of the specified parameters. This structure ensures a systematic approach to testing data management. The attributes containing the \textit{Params} expression in the name.

\subsection*{Attributes of prepared data}\label{subs:att_prep_data}

The \refsec{subs:test_attrib} discussed the preparation of data with parameters in this case we need to prepare the data to be able to accept and work with these parameters. The interfaces provide guaranteed direction and enforce adherence to the specified structure. However, interfaces can limit the flexibility of the programmer, especially if we need to define methods that do the same thing but contain different input arguments. To ensure that developers retain sufficient freedom while allowing prepared data to conform to the structure they envision, attributes were introduced. The attributes are intended to define data preparation methods for the methods or classes under test, indicating whether the method involves deploying the prepared data or removing it.

The attributes are defined before the method responsible for handling the data. Their primary benefit lies in granting developers the ability to incorporate input parameters, enabling precise customization of data preparation and manipulation processes.
The approach ensures that data preparation and processing processes remain consistent with testing requirements while allowing developers to tailor them to the specific needs of individual test scenarios.

\subsection{Interface Layer}
The \textit{Interface Layer} consists of the interfaces that cover the preparation and management of test data and related services. The Layer ensures consistency and modularity in the way data is prepared for test scenarios, supporting a structured approach.

Some of the interfaces are used for data preparation. The interfaces for preparing data for the method under test are designed at the class and method level. The data preparation interfaces provide only non-parametric methods for recalling the prepared data and subsequent data cleaning.  The attributes defined in \refsec{subs:att_prep_data} prove the same function, but also allow arguments.  However, the attributes lead to more complex code, which is not needed when preparing data without arguments.

In addition to data preparation, the interfaces layer contains mechanisms for managing test services. The interfaces extend the test case and add additional functionality to the framework. One of them is used to register and initialize services in the container within the test framework. 
The interface provides a structured resource that the classes for preparing the data accept and can use according to the developer's thinking.
Another interface is for defining the databases to be used in the test case. 

\todo{database}

\subsection{Data Handling Layer}

The \textit{Data Handling Layer} is responsible for orchestrating the preparation, management, and cleanup of test data. The layer introduces key components to ensure the integrity and consistency of the testing environment.

The core of the \textit{Data Handling Layer} is a system that automates the execution of methods for deploying prepared data and cleaning. The handler enforces a deterministic order of execution, ensuring that all preparatory logic is executed before the test is run and that cleanup operations are then reliably performed. In addition, the layer contains exception handling mechanisms that guarantee proper cleanup even in situations where tests fail unexpectedly.

The \texttt{Preparation data store} complements the handler by providing a centralized repository to manage data preparation instances associated with test methods. The store optimizes test execution by caching prepared data, reducing redundant computations, and improving performance. Additionally, the store is implemented with thread safety to support concurrent test executions in multithreaded environments.

\subsection{Integration Layer}
\textit{Integration Layer} aims to increase the efficiency of attribute execution and promote modularity through service-oriented design.
The \texttt{Attribute Count Storage} is critical in ensuring proper execution of data preparation. The \texttt{Attribute Count Storage} monitors the invocation of attributes applied to test methods, preventing duplicate execution of methods for preparing and cleaning test data when multiple attributes are stored on top of each other. This mechanism ensures that all preparatory logic runs as expected while maintaining efficiency.

In order to improve the separation of preparatory logic, the \texttt{Provider Store} framework is employed as a service provider. This component facilitates the implementation of dependency injection principles, enabling developers to dynamically register and incorporate services during testing. This methodology allows the framework to integrate effortlessly with established dependency injection frameworks, such as \texttt{Microsoft.Extensions.DependencyInjection}\footnote{\href{https://learn.microsoft.com/en-us/dotnet/core/extensions/dependency-injection}{https://learn.microsoft.com/en-us/dotnet/core/extensions/dependency-injection}}.


\section{NUnit Integration}
The framework achieves seamless integration with NUnit by extending its lifecycle through the use of custom hooks. We facilitate NUnit integration by implementing the \texttt{ITestAction} interface, which provides NUnit attributes with methods that enable the execution of logic both prior to and after the execution of a test.

Methods within the \texttt{ITestAction} interface, such as \texttt{BeforeTest} and \texttt{AfterTest}, are overridden to introduce steps for preparing data before test execution, as well as performing post-test cleanup and managing other services invoked and instantiated by the framework. This approach ensures that the data preparation and teardown processes are smoothly incorporated into the test execution flow without disrupting the inherent structure of NUnit's testing lifecycle.

For enhanced control over test behavior, test targets are specified within the attributes, ensuring that custom logic is applied to individual test methods. Moreover, the architecture is designed to support extensibility, enabling the targeting of entire test classes or namespaces, thereby allowing developers to apply bulk-processing logic as needed.

\subsection{Parallel Execution Support}
\todo{Parallel execution support}
Given the growing importance of parallelism in modern testing frameworks, the architecture has been designed to ensure reliable behavior in NUnit's \textit{parallel execution mode}. All lifecycle hooks, data preparation stores, and service providers are implemented with thread safety guarantees. This ensures that test data preparation and cleanup operations are executed consistently, even when tests are run concurrently across multiple threads.

